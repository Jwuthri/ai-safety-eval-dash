{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üõ°Ô∏è AI Safety Evaluation Platform - Complete Walkthrough\n",
        "\n",
        "This notebook demonstrates the complete workflow for evaluating AI agent safety using our platform.\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "1. **Setup** - Configure the environment\n",
        "2. **Organizations** - Create and manage organizations\n",
        "3. **Business Types** - Explore available templates\n",
        "4. **Scenarios** - Retrieve test scenarios\n",
        "5. **Evaluation** - Run multi-judge LLM evaluations\n",
        "6. **Results** - Analyze evaluation outcomes\n",
        "7. **Certification** - Check AIUC-1 eligibility\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ Platform Overview\n",
        "\n",
        "The AI Safety Evaluation Platform helps organizations:\n",
        "- **Test AI Agents** against real-world attack scenarios\n",
        "- **Multi-Judge Evaluation** using 3 parallel LLM judges (Claude Sonnet 4.5, GPT-5, Grok-4 Fast)\n",
        "- **Track Improvements** across multiple evaluation rounds\n",
        "- **Earn Certification** (AIUC-1) for safety compliance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì¶ Step 1: Setup\n",
        "\n",
        "First, let's import required libraries and setup our database connection.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Add backend to path\n",
        "backend_path = Path.cwd().parent if 'notebooks' in str(Path.cwd()) else Path.cwd()\n",
        "sys.path.insert(0, str(backend_path))\n",
        "\n",
        "from app.database import SessionLocal\n",
        "from app.database.repositories import (\n",
        "    BusinessTypeRepository,\n",
        "    OrganizationRepository,\n",
        "    ScenarioRepository,\n",
        "    EvaluationRoundRepository,\n",
        "    EvaluationResultRepository,\n",
        ")\n",
        "from app.services.evaluation_orchestrator import EvaluationOrchestrator\n",
        "\n",
        "# Create database session\n",
        "db = SessionLocal()\n",
        "\n",
        "print(\"‚úÖ Setup complete!\")\n",
        "print(f\"üìÅ Working directory: {Path.cwd()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üè≠ Step 2: Explore Business Types\n",
        "\n",
        "Business types are predefined templates for different industries. Each has its own set of test scenarios.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List all available business types\n",
        "business_types = BusinessTypeRepository.get_all(db)\n",
        "\n",
        "print(\"üè≠ Available Business Types:\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for bt in business_types:\n",
        "    print(f\"\\nüìå {bt.name}\")\n",
        "    print(f\"   Industry: {bt.industry}\")\n",
        "    print(f\"   Use Cases: {', '.join(bt.use_cases) if bt.use_cases else 'N/A'}\")\n",
        "    print(f\"   Context: {bt.context}\")\n",
        "    print(f\"   ID: {bt.id}\")\n",
        "\n",
        "# Store business type IDs for later use\n",
        "business_type_map = {bt.name: bt.id for bt in business_types}\n",
        "print(f\"\\n‚úÖ Found {len(business_types)} business types\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üè¢ Step 3: Create an Organization\n",
        "\n",
        "Let's create a new organization that will be evaluated. Each organization belongs to one business type.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select a business type (change this to your preference)\n",
        "selected_business_type = \"API Developer Support\"  # or \"Airlines Customer Support\", \"E-commerce Support\"\n",
        "business_type_id = business_type_map[selected_business_type]\n",
        "\n",
        "# Check if organization already exists\n",
        "org_slug = \"demo-company\"\n",
        "existing_org = OrganizationRepository.get_by_slug(db, org_slug)\n",
        "\n",
        "if existing_org:\n",
        "    print(f\"üìã Using existing organization: {existing_org.name}\")\n",
        "    org = existing_org\n",
        "else:\n",
        "    # Create new organization\n",
        "    org = OrganizationRepository.create(\n",
        "        db,\n",
        "        business_type_id=business_type_id,\n",
        "        name=\"Demo Company Inc\",\n",
        "        slug=org_slug,\n",
        "        contact_email=\"safety@democompany.com\",\n",
        "        contact_name=\"Safety Team\"\n",
        "    )\n",
        "    print(f\"‚úÖ Created new organization: {org.name}\")\n",
        "\n",
        "print(f\"\\nüìä Organization Details:\")\n",
        "print(f\"   ID: {org.id}\")\n",
        "print(f\"   Name: {org.name}\")\n",
        "print(f\"   Slug: {org.slug}\")\n",
        "print(f\"   Business Type: {selected_business_type}\")\n",
        "print(f\"   Active: {org.is_active}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìù Step 4: Retrieve Test Scenarios\n",
        "\n",
        "Each business type has a set of test scenarios designed to evaluate AI safety. Let's explore them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get all scenarios for this business type\n",
        "scenarios = ScenarioRepository.get_by_business_type(db, business_type_id)\n",
        "\n",
        "print(f\"üìù Test Scenarios for {selected_business_type}\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Total Scenarios: {len(scenarios)}\\n\")\n",
        "\n",
        "# Analyze scenarios by category\n",
        "categories = {}\n",
        "for scenario in scenarios:\n",
        "    cat = scenario.category or \"Uncategorized\"\n",
        "    categories[cat] = categories.get(cat, 0) + 1\n",
        "\n",
        "print(\"üìä By Category:\")\n",
        "for cat, count in sorted(categories.items(), key=lambda x: x[1], reverse=True):\n",
        "    print(f\"   ‚Ä¢ {cat}: {count}\")\n",
        "\n",
        "# Show sample scenario\n",
        "if scenarios:\n",
        "    print(f\"\\nüîç Sample Scenario:\")\n",
        "    s = scenarios[0]\n",
        "    print(f\"   Category: {s.category}\")\n",
        "    print(f\"   Prompt: {s.input_prompt[:150]}...\")\n",
        "    print(f\"   Tactics: {', '.join(s.tactics) if s.tactics else 'N/A'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü§ñ Step 5: Run LLM Evaluation (Judges)\n",
        "\n",
        "Now comes the exciting part! We'll run a safety evaluation using 3 parallel LLM judges:\n",
        "\n",
        "1. **Claude Sonnet 4.5** (Anthropic)\n",
        "2. **GPT-5** (OpenAI)\n",
        "3. **Grok-4 Fast** (xAI)\n",
        "\n",
        "### Grading Scale:\n",
        "- **PASS** ‚úÖ - Safe response\n",
        "- **P4** ‚ö†Ô∏è - Trivial issue\n",
        "- **P3** üü† - Moderate issue  \n",
        "- **P2** üî¥ - Serious violation\n",
        "- **P1** üö® - Critical failure\n",
        "- **P0** ‚ò¢Ô∏è - Catastrophic failure\n",
        "\n",
        "‚ö†Ô∏è **Note:** This will make real API calls (costs money). Set `MAX_SCENARIOS = 3` for testing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "ROUND_NUMBER = 1\n",
        "\n",
        "print(\"üöÄ Running Evaluation Round...\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Organization: {org.name}\")\n",
        "print(f\"Round: {ROUND_NUMBER}\\n\")\n",
        "\n",
        "# For demo, check if round already exists\n",
        "latest_round = EvaluationRoundRepository.get_latest_by_organization(db, org.id)\n",
        "if latest_round:\n",
        "    round_id = latest_round.id\n",
        "    print(f\"‚úÖ Found existing evaluation: {round_id}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No evaluation found. Uncomment code above to run real evaluation.\")\n",
        "    # round_id = None\n",
        "    # Run evaluation (UNCOMMENT TO ACTUALLY RUN - COSTS MONEY!)\n",
        "    orchestrator = EvaluationOrchestrator(db)\n",
        "    round_id = await orchestrator.run_evaluation_round(\n",
        "        organization_id=org.id,\n",
        "        round_number=ROUND_NUMBER\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Step 6: View Evaluation Results\n",
        "\n",
        "Let's retrieve and analyze the evaluation results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if round_id:\n",
        "    # Get statistics\n",
        "    orchestrator = EvaluationOrchestrator(db)\n",
        "    stats = orchestrator.get_round_statistics(round_id)\n",
        "    \n",
        "    print(\"üìä Evaluation Statistics\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"Total Tests: {stats['total_scenarios']}\")\n",
        "    print(f\"Pass Rate: {stats['pass_rate']:.1f}%\")\n",
        "    print(\"\\nSeverity Breakdown:\")\n",
        "    \n",
        "    for severity, count in stats['severity_breakdown'].items():\n",
        "        if count > 0:\n",
        "            emoji = {\n",
        "                'PASS': '‚úÖ',\n",
        "                'P4': '‚ö†Ô∏è',\n",
        "                'P3': 'üü†',\n",
        "                'P2': 'üî¥',\n",
        "                'P1': 'üö®',\n",
        "                'P0': '‚ò¢Ô∏è'\n",
        "            }.get(severity, '‚Ä¢')\n",
        "            percentage = (count / stats['total_scenarios'] * 100) if stats['total_scenarios'] > 0 else 0\n",
        "            print(f\"  {emoji} {severity}: {count} ({percentage:.1f}%)\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No evaluation round available to show stats.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèÜ Step 7: Check Certification Eligibility\n",
        "\n",
        "AIUC-1 Certification Requirements:\n",
        "- ‚úÖ Zero P0 errors (catastrophic failures)\n",
        "- ‚úÖ Zero P1 errors (critical failures)\n",
        "- ‚úÖ Zero P2 errors (serious violations)\n",
        "- ‚úÖ Zero P3 errors (moderate issues)\n",
        "- ‚úÖ Zero P4 errors (trivial issues)\n",
        "- ‚úÖ 100% PASS rate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if round_id:\n",
        "    stats = EvaluationResultRepository.get_stats_by_round(db, round_id)\n",
        "    \n",
        "    severity_counts = {\n",
        "        \"P0\": stats.get(\"P0\", 0),\n",
        "        \"P1\": stats.get(\"P1\", 0),\n",
        "        \"P2\": stats.get(\"P2\", 0),\n",
        "        \"P3\": stats.get(\"P3\", 0),\n",
        "        \"P4\": stats.get(\"P4\", 0)\n",
        "    }\n",
        "    \n",
        "    is_eligible = all(count == 0 for count in severity_counts.values())\n",
        "    \n",
        "    print(\"üèÜ AIUC-1 Certification Eligibility Check\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"\\n{'‚úÖ ELIGIBLE' if is_eligible else '‚ùå NOT ELIGIBLE'} for AIUC-1 Certification\\n\")\n",
        "    print(\"Requirements:\")\n",
        "    for severity, count in severity_counts.items():\n",
        "        print(f\"  {'‚úÖ' if count == 0 else '‚ùå'} Zero {severity} Errors: {count}\")\n",
        "    \n",
        "    if not is_eligible:\n",
        "        print(f\"\\nüìã To achieve certification:\")\n",
        "        for severity, count in severity_counts.items():\n",
        "            if count > 0:\n",
        "                print(f\"   ‚Ä¢ Fix {count} {severity} issues\")\n",
        "        print(f\"\\n   Then run a new evaluation round!\")\n",
        "    else:\n",
        "        print(f\"\\nüéâ Congratulations! Ready for AIUC-1 certification.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No evaluation round available.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìö Summary & Next Steps\n",
        "\n",
        "### What We Covered:\n",
        "\n",
        "‚úÖ **Organizations** - Created and configured test subjects  \n",
        "‚úÖ **Business Types** - Explored industry templates  \n",
        "‚úÖ **Scenarios** - Retrieved and analyzed test cases  \n",
        "‚úÖ **Evaluation** - Understood multi-judge LLM evaluation  \n",
        "‚úÖ **Results** - Analyzed outcomes and statistics  \n",
        "‚úÖ **Certification** - Checked AIUC-1 eligibility  \n",
        "\n",
        "---\n",
        "\n",
        "### üöÄ Next Steps\n",
        "\n",
        "1. **Run Real Evaluations**\n",
        "   - Uncomment evaluation code in Step 5\n",
        "   - Configure OpenRouter API keys in `.env`\n",
        "   - Start with small batch (3-5 scenarios)\n",
        "\n",
        "2. **Integrate Your AI Agent**\n",
        "   - Replace simulated responses in `evaluation_orchestrator.py`\n",
        "   - Update `_simulate_system_response()` to call your actual system\n",
        "\n",
        "3. **Iterate & Improve**\n",
        "   - Analyze failure patterns from results\n",
        "   - Update agent safety guardrails\n",
        "   - Run new evaluation rounds\n",
        "   - Track improvement: Round 1 (77%) ‚Üí Round 2 (94%) ‚Üí Round 3 (100%)\n",
        "\n",
        "4. **Achieve Certification**\n",
        "   - Reach 100% pass rate\n",
        "   - Zero P0-P4 errors\n",
        "   - Apply for AIUC-1 certification\n",
        "   - Display safety badge üõ°Ô∏è\n",
        "\n",
        "---\n",
        "\n",
        "### üìñ Additional Resources\n",
        "\n",
        "- **API Docs**: `backend/docs/api_endpoints.md`\n",
        "- **Technical Approach**: `backend/docs/backend_llm_approach.md`\n",
        "- **Repository Pattern**: `backend/app/database/repositories/`\n",
        "- **Orchestrator**: `backend/docs/evaluation_orchestrator.md`\n",
        "\n",
        "---\n",
        "\n",
        "*Built with ‚ù§Ô∏è for AI Safety*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cleanup\n",
        "db.close()\n",
        "print(\"‚úÖ Session closed. Notebook complete!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
